{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65ac6534",
   "metadata": {},
   "source": [
    "## Make 3 dataset consisting of 3 humor categories which each contains 6k jokes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736aba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "\n",
    "\n",
    "os.chdir(\"C:/Users/patry/Desktop/Uni/Core topics AI/LLM project\")\n",
    "print(os.getcwd())\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"train.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    header=None,                 \n",
    "    names=[\"label\", \"joke\"],     \n",
    "    encoding=\"utf-8\",\n",
    "    engine=\"python\",\n",
    "    on_bad_lines=\"skip\"\n",
    ")\n",
    "\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    " \n",
    "def ascii_ratio(s: str) -> float:\n",
    "    if not s:\n",
    "        return 0.0\n",
    "    printable = set(string.printable)\n",
    "    return sum(ch in printable for ch in s) / len(s)\n",
    "\n",
    "def fix_mojibake(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    try:\n",
    "        # reinterpret as latin-1 and decode as utf-8\n",
    "        return text.encode(\"latin-1\").decode(\"utf-8\")\n",
    "    except (UnicodeEncodeError, UnicodeDecodeError):\n",
    "        return text\n",
    "\n",
    "\n",
    "\n",
    "df = df.dropna(subset=[\"joke\"])\n",
    "df[\"joke\"] = df[\"joke\"].astype(str).str.strip()\n",
    "\n",
    "df[\"joke\"] = df[\"joke\"].apply(fix_mojibake)\n",
    "\n",
    "# drop obvious gibberish\n",
    "df = df[df[\"joke\"].apply(ascii_ratio) > 0.85]\n",
    "\n",
    "# sample 2k dark-ish internet jokes\n",
    "dark_df = df.sample(n=6000, random_state=42)\n",
    "dark_df[[\"joke\"]].to_csv(\"dark_jokes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc631d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dad_jokes_complete.csv\", header=None, names=[\"joke\"])\n",
    "\n",
    "# Drop NaN & strip whitespace\n",
    "df = df.dropna(subset=[\"joke\"])\n",
    "df[\"joke\"] = df[\"joke\"].astype(str).str.strip()\n",
    "\n",
    "# Try to fix mojibake\n",
    "def fix_mojibake(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    try:\n",
    "        return text.encode(\"latin-1\").decode(\"utf-8\")\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "df[\"joke\"] = df[\"joke\"].apply(fix_mojibake)\n",
    "\n",
    "# Remove gibberish using ascii_ratio\n",
    "def ascii_ratio(s: str) -> float:\n",
    "    if not s:\n",
    "        return 0.0\n",
    "    printable = set(string.printable)\n",
    "    return sum(ch in printable for ch in s) / len(s)\n",
    "\n",
    "df = df[df[\"joke\"].apply(ascii_ratio) > 0.85]\n",
    "\n",
    "# remove overly long entries \n",
    "df = df[df[\"joke\"].str.len() < 400]\n",
    "\n",
    "# Save cleaned dataset\n",
    "df.to_csv(\"dad_jokes_cleaned.csv\", index=False)\n",
    "print(\"Cleaned dad jokes:\", df.shape)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"dad_jokes_cleaned.csv\")\n",
    "\n",
    "dad_df = df.sample(n=6000, random_state=42)  \n",
    "dad_df.to_csv(\"dad_jokes_sampled.csv\", index=False)\n",
    "\n",
    "print(\"Saved sampled dad jokes:\", dad_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6ea44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import os \n",
    "\n",
    "\n",
    "os.chdir(\"C:/Users/patry/Desktop/Uni/Core topics AI/LLM project\")\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"shortjokes.csv\", header=None, names=[\"joke\"])\n",
    "\n",
    "# Drop NaN & strip whitespace\n",
    "df = df.dropna(subset=[\"joke\"])\n",
    "df[\"joke\"] = df[\"joke\"].astype(str).str.strip()\n",
    "\n",
    "\n",
    "def fix_mojibake(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    try:\n",
    "        return text.encode(\"latin-1\").decode(\"utf-8\")\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "df[\"joke\"] = df[\"joke\"].apply(fix_mojibake)\n",
    "\n",
    "\n",
    "def ascii_ratio(s: str) -> float:\n",
    "    if not s:\n",
    "        return 0.0\n",
    "    printable = set(string.printable)\n",
    "    return sum(ch in printable for ch in s) / len(s)\n",
    "\n",
    "df = df[df[\"joke\"].apply(ascii_ratio) > 0.85]\n",
    "\n",
    "\n",
    "df = df[df[\"joke\"].str.len() < 400]\n",
    "\n",
    "# Save cleaned dataset\n",
    "df.to_csv(\"shortjokes_cleaned.csv\", index=False)\n",
    "print(\"Cleaned short jokes:\", df.shape)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"shortjokes_cleaned.csv\")\n",
    "\n",
    "short_df = df.sample(n=6000, random_state=42)  \n",
    "short_df.to_csv(\"short_jokes_sampled.csv\", index=False)\n",
    "\n",
    "print(\"Saved sampled short jokes:\", short_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1535c3",
   "metadata": {},
   "source": [
    "# Make csv files into instruction JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34e1a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Working directory:\", os.getcwd())\n",
    "\n",
    "def csv_to_jsonl(csv_path, jsonl_path, instruction_text, sep=\",\", column=\"joke\"):\n",
    "    df = pd.read_csv(csv_path, sep=sep)\n",
    "\n",
    "    # If the column name is wrong (like \"joke;;\"), rename it\n",
    "    if column not in df.columns:\n",
    "        # Try to detect the joke column\n",
    "        for col in df.columns:\n",
    "            if \"joke\" in col.lower():\n",
    "                df = df.rename(columns={col: \"joke\"})\n",
    "                break\n",
    "\n",
    "    with open(jsonl_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for joke in df[\"joke\"]:\n",
    "            example = {\n",
    "                \"instruction\": instruction_text,\n",
    "                \"input\": \"\",\n",
    "                \"output\": joke\n",
    "            }\n",
    "            f.write(json.dumps(example, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    print(f\"Created: {jsonl_path}\")\n",
    "\n",
    "\n",
    "\n",
    "# Dad jokes — normal CSV\n",
    "csv_to_jsonl(\n",
    "    \"dad_jokes_sampled.csv\",\n",
    "    \"dad_jokes.jsonl\",\n",
    "    \"Tell a dad joke.\",\n",
    "    sep=\",\",\n",
    "    column=\"joke\"\n",
    ")\n",
    "\n",
    "# Dark jokes — semicolon separator, column is \"joke;;\"\n",
    "csv_to_jsonl(\n",
    "    \"dark_jokes.csv\",\n",
    "    \"dark_jokes.jsonl\",\n",
    "    \"Tell a dark humor joke.\",\n",
    "    sep=\";\",           \n",
    "    column=\"joke;;\"    \n",
    ")\n",
    "\n",
    "# Sarcastic/short jokes — normal CSV\n",
    "csv_to_jsonl(\n",
    "    \"short_jokes_sampled.csv\",\n",
    "    \"short_jokes.jsonl\",\n",
    "    \"Tell a short joke.\",\n",
    "    sep=\",\",\n",
    "    column=\"joke\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326ad64e",
   "metadata": {},
   "source": [
    "## Merge all jokes into 1 JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b90477",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_merge = [\n",
    "    \"dad_jokes.jsonl\",\n",
    "    \"dark_jokes.jsonl\",\n",
    "    \"short_jokes.jsonl\"\n",
    "]\n",
    "\n",
    "output_file = \"humor_3cat.jsonl\"\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for fname in files_to_merge:\n",
    "        with open(fname, \"r\", encoding=\"utf-8\") as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)\n",
    "\n",
    "print(\"Merged into:\", output_file)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
